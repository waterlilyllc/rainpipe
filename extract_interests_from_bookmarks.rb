#!/usr/bin/env ruby

require 'dotenv'
Dotenv.load('/var/git/rainpipe/.env')

require 'json'
require 'net/http'
require 'uri'
require 'date'
require 'time'
require 'fileutils'
require_relative 'raindrop_client'

class InterestExtractor
  OPENAI_API_URL = 'https://api.openai.com/v1/chat/completions'
  OUTPUT_DIR = './data/interests'
  
  def initialize
    @api_key = ENV['OPENAI_API_KEY']
    @model = ENV['GPT_MODEL'] || 'gpt-4o-mini'
    FileUtils.mkdir_p(OUTPUT_DIR)
  end
  
  def extract_from_recent_bookmarks(days: 30)
    puts "ğŸ“š ç›´è¿‘#{days}æ—¥é–“ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã‚’å–å¾—ä¸­..."
    
    # Raindropã‹ã‚‰å…¨ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã‚’å–å¾—ã—ã¦æ—¥ä»˜ã§ãƒ•ã‚£ãƒ«ã‚¿
    client = RaindropClient.new
    end_date = Date.today
    start_date = end_date - days
    
    # å…¨ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸJSONã‹ã‚‰ï¼‰
    all_bookmarks = client.load_all_bookmarks
    
    # æ—¥ä»˜ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    bookmarks = all_bookmarks.select do |bookmark|
      created_date = Date.parse(bookmark['created'])
      created_date >= start_date && created_date <= end_date
    rescue
      false
    end
    puts "âœ… #{bookmarks.length}ä»¶ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã‚’å–å¾—ã—ã¾ã—ãŸ"
    
    # GPTã§åˆ†æ
    puts "\nğŸ¤– GPTã§é–¢å¿ƒãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºä¸­..."
    analysis = analyze_bookmarks_with_gpt(bookmarks, start_date, end_date)
    
    if analysis
      # çµæœã‚’ä¿å­˜
      save_analysis(analysis, start_date, end_date)
      display_results(analysis)
    else
      puts "âŒ åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ"
    end
  end
  
  private
  
  def analyze_bookmarks_with_gpt(bookmarks, start_date, end_date)
    # ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
    bookmark_text = format_bookmarks_for_gpt(bookmarks)
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    prompt = build_analysis_prompt(bookmark_text, start_date, end_date)
    
    # GPT APIã‚’å‘¼ã³å‡ºã—
    response = call_gpt_api(prompt)
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
    parse_gpt_response(response)
  end
  
  def format_bookmarks_for_gpt(bookmarks)
    # æœ€æ–°ã®50ä»¶ã«çµã‚‹ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å¯¾ç­–ï¼‰
    recent_bookmarks = bookmarks.sort_by { |b| b['created'] }.reverse.first(50)
    
    recent_bookmarks.map do |bookmark|
      parts = []
      parts << "ã€#{format_date(bookmark['created'])}ã€‘"
      parts << "ã‚¿ã‚¤ãƒˆãƒ«: #{bookmark['title']}" if bookmark['title']
      parts << "URL: #{bookmark['link']}" if bookmark['link']
      parts << "ã‚¿ã‚°: #{bookmark['tags'].join(', ')}" if bookmark['tags'] && bookmark['tags'].any?
      parts << "èª¬æ˜: #{bookmark['excerpt']}" if bookmark['excerpt'] && !bookmark['excerpt'].empty?
      parts.join("\n")
    end.join("\n\n---\n\n")
  end
  
  def build_analysis_prompt(bookmark_text, start_date, end_date)
    <<~PROMPT
      ã‚ãªãŸã¯å„ªç§€ãªãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
      ä»¥ä¸‹ã¯ç§ã®#{start_date}ã‹ã‚‰#{end_date}ã¾ã§ã®#{30}æ—¥é–“ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã§ã™ã€‚
      ã“ã‚Œã‚‰ã‹ã‚‰ç§ã®é–¢å¿ƒäº‹ã€èˆˆå‘³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã€çŸ¥è­˜æ¬²æ±‚ã®æ–¹å‘æ€§ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

      ï¼œãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ä¸€è¦§ï¼
      #{bookmark_text}

      ä»¥ä¸‹ã®è¦³ç‚¹ã§åˆ†æã—ã€JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

      1. **ã‚³ã‚¢ãªé–¢å¿ƒäº‹** - ç¹°ã‚Šè¿”ã—ç¾ã‚Œã‚‹ä¸­å¿ƒçš„ãªãƒ†ãƒ¼ãƒ
      2. **æ–°ã—ã„èˆˆå‘³** - æœ€è¿‘ã«ãªã£ã¦ç¾ã‚ŒãŸæ–°ã—ã„ãƒˆãƒ”ãƒƒã‚¯
      3. **æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯** - èˆˆå‘³ã‚’æŒã£ã¦ã„ã‚‹æŠ€è¡“ãƒ»ãƒ„ãƒ¼ãƒ«ãƒ»ã‚µãƒ¼ãƒ“ã‚¹
      4. **å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º** - å„ãƒˆãƒ”ãƒƒã‚¯ã®å­¦ç¿’æ®µéšï¼ˆåˆå¿ƒè€…/å®Ÿè·µ/æ·±æ˜ã‚Šï¼‰
      5. **é–¢é€£æ€§ãƒãƒƒãƒ—** - ãƒˆãƒ”ãƒƒã‚¯é–“ã®é–¢é€£æ€§

      JSONå½¢å¼ï¼š
      {
        "analysis_period": {
          "start": "#{start_date}",
          "end": "#{end_date}",
          "total_bookmarks": æ•°å€¤
        },
        "core_interests": [
          {
            "keyword": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆè‹±èªã®å ´åˆã¯ãã®ã¾ã¾ã€æ—¥æœ¬èªã‚‚å¯ï¼‰",
            "frequency": å‡ºç¾å›æ•°,
            "importance": 1-10ã®é‡è¦åº¦,
            "category": "ã‚«ãƒ†ã‚´ãƒªï¼ˆtechnology/business/lifestyle/learningç­‰ï¼‰",
            "context": "ãªãœã“ã‚Œã«èˆˆå‘³ãŒã‚ã‚‹ã®ã‹ã€ã©ã†ã„ã†æ–‡è„ˆã‹",
            "examples": ["é–¢é€£ã™ã‚‹ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã®ã‚¿ã‚¤ãƒˆãƒ«ä¾‹ã‚’2-3å€‹"],
            "related_hot_words": [
              {
                "word": "é–¢é€£ã™ã‚‹æ³¨ç›®ãƒ¯ãƒ¼ãƒ‰",
                "reason": "ãªãœé–¢é€£ã—ã¦ã„ã¦æ³¨ç›®ã™ã¹ãã‹"
              }
            ]
          }
        ],
        "emerging_interests": [
          {
            "keyword": "æ–°ã—ãå‡ºç¾ã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
            "first_seen": "åˆå‡ºæ—¥",
            "growth_rate": "æ€¥é€Ÿ/é€šå¸¸/ç·©ã‚„ã‹",
            "potential": "ä»Šå¾Œã®ç™ºå±•å¯èƒ½æ€§",
            "related_to": ["æ—¢å­˜ã®é–¢å¿ƒäº‹ã¨ã®é–¢é€£"]
          }
        ],
        "technology_stack": {
          "languages": ["ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª"],
          "frameworks": ["ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯/ãƒ©ã‚¤ãƒ–ãƒ©ãƒª"],
          "tools": ["ãƒ„ãƒ¼ãƒ«/ã‚µãƒ¼ãƒ“ã‚¹"],
          "platforms": ["ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ "]
        },
        "learning_phases": {
          "exploring": ["æ¢ç´¢æ®µéšã®ãƒˆãƒ”ãƒƒã‚¯"],
          "practicing": ["å®Ÿè·µæ®µéšã®ãƒˆãƒ”ãƒƒã‚¯"],
          "deepening": ["æ·±æ˜ã‚Šæ®µéšã®ãƒˆãƒ”ãƒƒã‚¯"]
        },
        "interest_clusters": [
          {
            "cluster_name": "é–¢é€£ãƒˆãƒ”ãƒƒã‚¯ã®ã‚°ãƒ«ãƒ¼ãƒ—å",
            "keywords": ["å«ã¾ã‚Œã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"],
            "theme": "å…±é€šãƒ†ãƒ¼ãƒ"
          }
        ],
        "insights": {
          "summary": "å…¨ä½“çš„ãªèˆˆå‘³ã®å‚¾å‘ï¼ˆ2-3æ–‡ï¼‰",
          "recommendations": ["ä»Šå¾Œãƒã‚§ãƒƒã‚¯ã™ã¹ããƒˆãƒ”ãƒƒã‚¯"],
          "blind_spots": ["è¦‹è½ã¨ã—ã¦ã„ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹é–¢é€£åˆ†é‡"]
        }
      }

      æ³¨æ„äº‹é …ï¼š
      - è£½å“åã€ã‚µãƒ¼ãƒ“ã‚¹åã¯æ­£ç¢ºã«æŠ½å‡º
      - æŠ€è¡“ç”¨èªã¯ç•¥èªã‚‚æ­£å¼åç§°ã‚‚è€ƒæ…®
      - æ—¥æœ¬èªã¨è‹±èªã®ä¸¡æ–¹ã‚’é©åˆ‡ã«æ‰±ã†
      - ã‚ã¾ã‚Šã«ä¸€èˆ¬çš„ãªå˜èªï¼ˆä¾‹ï¼šã€Œä½¿ã„æ–¹ã€ã€Œæ–¹æ³•ã€ï¼‰ã¯é™¤å¤–
      - é‡è¦åº¦ã¯å‡ºç¾é »åº¦ã ã‘ã§ãªãã€æ–‡è„ˆã§ã®é‡è¦æ€§ã‚‚è€ƒæ…®
      - **é‡è¦**: å„core_interestã«ã¯å¿…ãš5å€‹ã®related_hot_wordsã‚’å«ã‚ã¦ãã ã•ã„
      - related_hot_wordsã¯ã€ãã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ä¸€ç·’ã«æ³¨ç›®ã™ã¹ãæœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¯ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ãã ã•ã„
      - ä¾‹: "AI"ãªã‚‰â†’["RAG", "Agent", "Fine-tuning", "Multimodal", "Local LLM"]ã®ã‚ˆã†ãªé–¢é€£ãƒ¯ãƒ¼ãƒ‰
    PROMPT
  end
  
  def call_gpt_api(prompt)
    uri = URI(OPENAI_API_URL)
    http = Net::HTTP.new(uri.host, uri.port)
    http.use_ssl = true
    http.read_timeout = 60  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’60ç§’ã«è¨­å®š
    
    request = Net::HTTP::Post.new(uri)
    request['Authorization'] = "Bearer #{@api_key}"
    request['Content-Type'] = 'application/json'
    
    request.body = {
      model: @model,
      messages: [
        {
          role: 'system',
          content: 'ã‚ãªãŸã¯ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ´å¯Ÿã‚’å°ãå‡ºã™å°‚é–€å®¶ã§ã™ã€‚æ§‹é€ åŒ–ã•ã‚ŒãŸJSONã§åˆ†æçµæœã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚'
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      temperature: 0.7,
      max_tokens: 4000,
      response_format: { type: "json_object" }
    }.to_json
    
    response = http.request(request)
    JSON.parse(response.body)
  rescue => e
    puts "API Error: #{e.message}"
    nil
  end
  
  def parse_gpt_response(response)
    return nil unless response
    
    if response['error']
      puts "GPT Error: #{response['error']['message']}"
      return nil
    end
    
    content = response.dig('choices', 0, 'message', 'content')
    return nil unless content
    
    JSON.parse(content)
  rescue JSON::ParserError => e
    puts "JSON Parse Error: #{e.message}"
    puts "Content: #{content}"
    nil
  end
  
  def save_analysis(analysis, start_date, end_date)
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«å
    timestamp = Time.now.strftime('%Y%m%d_%H%M%S')
    filename = "interest_analysis_#{timestamp}.json"
    filepath = File.join(OUTPUT_DIR, filename)
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    full_data = {
      'generated_at' => Time.now.iso8601,
      'analysis_period' => {
        'start' => start_date.to_s,
        'end' => end_date.to_s
      },
      'analysis' => analysis
    }
    
    # ä¿å­˜
    File.write(filepath, JSON.pretty_generate(full_data))
    puts "\nğŸ’¾ åˆ†æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: #{filepath}"
    
    # æœ€æ–°ç‰ˆã¨ã—ã¦ã‚‚ä¿å­˜
    latest_path = File.join(OUTPUT_DIR, 'latest_analysis.json')
    File.write(latest_path, JSON.pretty_generate(full_data))
  end
  
  def display_results(analysis)
    puts "\nğŸ“Š åˆ†æçµæœ"
    puts "="*50
    
    # ã‚³ã‚¢é–¢å¿ƒäº‹
    puts "\nğŸ¯ ã‚³ã‚¢ãªé–¢å¿ƒäº‹ TOP5"
    analysis['core_interests'].first(5).each do |interest|
      puts "- #{interest['keyword']} (é‡è¦åº¦: #{interest['importance']}/10)"
      puts "  ã‚«ãƒ†ã‚´ãƒª: #{interest['category']}"
      puts "  æ–‡è„ˆ: #{interest['context']}"
      puts ""
    end
    
    # æ–°ã—ã„èˆˆå‘³
    if analysis['emerging_interests'] && analysis['emerging_interests'].any?
      puts "\nğŸŒ± æ–°ã—ãç¾ã‚ŒãŸèˆˆå‘³"
      analysis['emerging_interests'].each do |interest|
        puts "- #{interest['keyword']}"
        puts "  å¯èƒ½æ€§: #{interest['potential']}"
        puts ""
      end
    end
    
    # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
    if tech = analysis['technology_stack']
      puts "\nğŸ›  æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯"
      puts "è¨€èª: #{tech['languages'].join(', ')}" if tech['languages']
      puts "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: #{tech['frameworks'].join(', ')}" if tech['frameworks']
      puts "ãƒ„ãƒ¼ãƒ«: #{tech['tools'].join(', ')}" if tech['tools']
    end
    
    # ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
    if insights = analysis['insights']
      puts "\nğŸ’¡ ã‚¤ãƒ³ã‚µã‚¤ãƒˆ"
      puts insights['summary']
      
      if insights['recommendations'] && insights['recommendations'].any?
        puts "\næ¨å¥¨ãƒˆãƒ”ãƒƒã‚¯:"
        insights['recommendations'].each { |r| puts "- #{r}" }
      end
    end
  end
  
  def format_date(date_string)
    Date.parse(date_string).strftime('%m/%d')
  rescue
    date_string
  end
end

# å®Ÿè¡Œ
if __FILE__ == $0
  unless ENV['OPENAI_API_KEY']
    puts "âŒ Error: OPENAI_API_KEY environment variable is not set"
    puts "Please set it in your .env file or export it"
    exit 1
  end
  
  extractor = InterestExtractor.new
  extractor.extract_from_recent_bookmarks(days: 30)
end