#!/usr/bin/env ruby

require 'dotenv'
Dotenv.load('/var/git/rainpipe/.env')

require 'json'
require 'net/http'
require 'uri'
require 'time'

class TechTrendsFetcher
  TREND_SOURCES = [
    "GitHub Trending",
    "HackerNews",
    "Dev.to",
    "Stack Overflow trends",
    "Reddit programming"
  ]
  
  def fetch_programming_trends
    puts "ğŸ” ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ¥­ç•Œã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åé›†ä¸­..."
    
    # è¤‡æ•°ã®ã‚¯ã‚¨ãƒªã§æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æ¤œç´¢
    trend_queries = [
      "programming trends 2025 æœ€æ–°",
      "GitHub trending this week",
      "æ–°ã—ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ 2025",
      "é–‹ç™ºè€… æ³¨ç›® æŠ€è¡“ ãƒˆãƒ¬ãƒ³ãƒ‰",
      "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ è©±é¡Œ ãƒ„ãƒ¼ãƒ« æœ€æ–°"
    ]
    
    all_trends = {}
    
    trend_queries.each do |query|
      trends = search_trends(query)
      analyze_trends(trends, all_trends)
      sleep(1) # APIåˆ¶é™å¯¾ç­–
    end
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    trending_keywords = extract_trending_keywords(all_trends)
    
    # GPTã§ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ
    analyzed_trends = analyze_with_gpt(trending_keywords)
    
    save_trends(analyzed_trends)
    analyzed_trends
  end
  
  private
  
  def search_trends(query)
    uri = URI('https://www.googleapis.com/customsearch/v1')
    params = {
      key: ENV['GOOGLE_API_KEY'],
      cx: ENV['GOOGLE_CUSTOM_SEARCH_CX'],
      q: query,
      num: 10,
      dateRestrict: 'd7',
      lr: 'lang_ja'
    }
    uri.query = URI.encode_www_form(params)
    
    response = Net::HTTP.get_response(uri)
    
    if response.code == '200'
      data = JSON.parse(response.body)
      data['items'] || []
    else
      []
    end
  rescue => e
    puts "æ¤œç´¢ã‚¨ãƒ©ãƒ¼: #{e.message}"
    []
  end
  
  def analyze_trends(items, all_trends)
    items.each do |item|
      # ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‹ã‚‰æŠ€è¡“ç”¨èªã‚’æŠ½å‡º
      text = "#{item['title']} #{item['snippet']}".downcase
      
      # æŠ€è¡“é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
      tech_patterns = [
        /\b(rust|go|golang|python|javascript|typescript|ruby|java|kotlin|swift)\b/,
        /\b(react|vue|angular|svelte|nextjs|nuxt)\b/,
        /\b(ai|ml|machine learning|llm|gpt|claude|gemini)\b/,
        /\b(docker|kubernetes|k8s|cloud|aws|gcp|azure)\b/,
        /\b(wasm|webassembly|blockchain|web3|defi)\b/,
        /\b(devops|ci\/cd|github actions|gitlab)\b/,
        /\b(graphql|rest api|grpc|websocket)\b/,
        /\b(microservices|serverless|edge computing)\b/
      ]
      
      tech_patterns.each do |pattern|
        matches = text.scan(pattern)
        matches.each do |match|
          keyword = match.is_a?(Array) ? match[0] : match
          all_trends[keyword] ||= 0
          all_trends[keyword] += 1
        end
      end
    end
  end
  
  def extract_trending_keywords(all_trends)
    # å‡ºç¾é »åº¦ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½ã‚’å–å¾—
    all_trends.sort_by { |_, count| -count }
              .first(20)
              .map { |keyword, count| { keyword: keyword, frequency: count } }
  end
  
  def analyze_with_gpt(trending_keywords)
    return [] if trending_keywords.empty?
    
    prompt = build_trend_analysis_prompt(trending_keywords)
    
    uri = URI('https://api.openai.com/v1/chat/completions')
    http = Net::HTTP.new(uri.host, uri.port)
    http.use_ssl = true
    
    request = Net::HTTP::Post.new(uri)
    request['Authorization'] = "Bearer #{ENV['OPENAI_API_KEY']}"
    request['Content-Type'] = 'application/json'
    
    request.body = {
      model: ENV['GPT_MODEL'] || 'gpt-4o-mini',
      messages: [
        {
          role: 'system',
          content: 'ã‚ãªãŸã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ¥­ç•Œã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚'
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      temperature: 0.5,
      max_tokens: 2000,
      response_format: { type: "json_object" }
    }.to_json
    
    response = http.request(request)
    
    if response.code == '200'
      data = JSON.parse(response.body)
      content = data.dig('choices', 0, 'message', 'content')
      JSON.parse(content) rescue {}
    else
      {}
    end
  rescue => e
    puts "GPTåˆ†æã‚¨ãƒ©ãƒ¼: #{e.message}"
    {}
  end
  
  def build_trend_analysis_prompt(keywords)
    keyword_list = keywords.map { |k| "- #{k[:keyword]} (å‡ºç¾: #{k[:frequency]}å›)" }.join("\n")
    
    <<~PROMPT
      ä»¥ä¸‹ã¯ä»Šé€±ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°é–¢é€£è¨˜äº‹ã‹ã‚‰æŠ½å‡ºã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã™ï¼š
      
      #{keyword_list}
      
      ã“ã‚Œã‚‰ã‹ã‚‰ä»Šé€±ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ¥­ç•Œã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æã—ã€
      é–‹ç™ºè€…ãŒæ³¨ç›®ã™ã¹ããƒˆãƒƒãƒ—10ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¯ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
      
      JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
      {
        "trends": [
          {
            "keyword": "ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¯ãƒ¼ãƒ‰",
            "category": "ã‚«ãƒ†ã‚´ãƒªï¼ˆlanguage/framework/tool/conceptï¼‰",
            "importance": 1-10ã®é‡è¦åº¦,
            "reason": "ãªãœä»Šæ³¨ç›®ã™ã¹ãã‹",
            "related_topics": ["é–¢é€£ãƒˆãƒ”ãƒƒã‚¯1", "é–¢é€£ãƒˆãƒ”ãƒƒã‚¯2"],
            "use_cases": ["å…·ä½“çš„ãªä½¿ç”¨ä¾‹ã‚„å¿œç”¨åˆ†é‡"]
          }
        ],
        "summary": "ä»Šé€±ã®ãƒˆãƒ¬ãƒ³ãƒ‰å…¨ä½“ã®ã‚µãƒãƒªãƒ¼ï¼ˆ2-3æ–‡ï¼‰",
        "emerging": ["ä»Šå¾Œæ³¨ç›®ã•ã‚Œãã†ãªæ–°ã—ã„æŠ€è¡“"],
        "analysis_date": "#{Date.today}"
      }
    PROMPT
  end
  
  def save_trends(analyzed_trends)
    return if analyzed_trends.empty?
    
    data = {
      fetched_at: Time.now.iso8601,
      trends: analyzed_trends['trends'] || [],
      summary: analyzed_trends['summary'],
      emerging: analyzed_trends['emerging'] || []
    }
    
    Dir.mkdir('./data/tech_trends') unless Dir.exist?('./data/tech_trends')
    
    filename = "./data/tech_trends/trends_#{Time.now.strftime('%Y%m%d_%H%M%S')}.json"
    File.write(filename, JSON.pretty_generate(data))
    
    # æœ€æ–°ç‰ˆã‚‚ä¿å­˜
    File.write('./data/tech_trends/latest.json', JSON.pretty_generate(data))
    
    puts "âœ… ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’ä¿å­˜ã—ã¾ã—ãŸ"
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¯ãƒ¼ãƒ‰ã‚’è¡¨ç¤º
    if data[:trends].any?
      puts "\nğŸ“ˆ ä»Šé€±ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒˆãƒ¬ãƒ³ãƒ‰ TOP10:"
      data[:trends].each_with_index do |trend, idx|
        puts "\n#{idx + 1}. #{trend['keyword']} (é‡è¦åº¦: #{trend['importance']}/10)"
        puts "   ç†ç”±: #{trend['reason']}"
      end
      
      puts "\nğŸ’¡ ã‚µãƒãƒªãƒ¼: #{data[:summary]}"
    end
  end
end

# å®Ÿè¡Œ
if __FILE__ == $0
  fetcher = TechTrendsFetcher.new
  fetcher.fetch_programming_trends
end